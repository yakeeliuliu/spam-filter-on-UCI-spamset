mean_standard_dev <- function(dataset)
{
  # Expects the training set.
  # Calculates mean and standard deviation of each feature in the training
  # dataset. Stores the results in a matrix, which is returned to the calling routine.
  # mean_sd_matrix[i, 1] = mean for that feature given that it's spam
  # mean_sd_matrix[i, 2] = mean for that feature given that it's not spam
  # mean_sd_matrix[i, 3] = standard deviation for that feature given that it's spam
  # mean_sd_matrix[i, 4] = standard deviation for that feature given that it's not spam
  
  # Create an empty matrix to put feature means/standard deviations in
  num_col <- ncol(dataset)
  mean_sd_matrix <- matrix(0, nrow = (num_col - 1), ncol = 4)
  
  # Loop through each column of the dataset and calculate the mean and
  # standard deviations of each feature given that it's spam/not spam.
  # Place the results in the corresponding columns of 'mean_sd_matrix'.
  # Used https://stackoverflow.com/questions/1660124/how-to-sum-a-variable-by-group#1661144
  # as a reference.
  i <- 1:(num_col-1)
  means <- aggregate(dataset[, i], by=list(dataset[, num_col]), FUN=mean)
  means <- as.matrix(means)
  standard_devs <- aggregate(dataset[, i], by=list(dataset[, num_col]), FUN=sd)
  standard_devs <- as.matrix(standard_devs)
  
  mean_sd_matrix[, 1] <- means[2, (2:num_col)]
  mean_sd_matrix[, 2] <- means[1, (2:num_col)]
  mean_sd_matrix[, 3] <- standard_devs[2, (2:num_col)]
  mean_sd_matrix[, 4] <- standard_devs[1, (2:num_col)]
  
  # So as to not mess up future calculations, if there are any features
  # with 0.0 for their means and/or standard deviations, replace those values
  # with 0.0001.
  # Used https://stackoverflow.com/questions/9439619/replace-all-values-in-a-matrix-0-1-with-0
  # as a reference.
  mean_sd_matrix[mean_sd_matrix == 0.0] <- 0.0001
  return(mean_sd_matrix)
}

get_class_predictions <- function(dataset, mean_sd_matrix)
{
  # Expects the test set and matrix of feature means and standard deviations.
  # Creates a matrix of probabilities where each row represents a data sample.
  # Each column represents:
  # probability_matrix[i, 1] = probability of that data sample being spam
  # probability_matrix[i, 2] = probability of that data sample not being spam
  # Returns probability_matrix to the calling routine.
  
  num_samples <- nrow(dataset)
  num_cols <- ncol(dataset)
  
  # Stores the results of the PDF on each feature for each sample, given that the sample is spam/not spam
  conditional_spam <- matrix(0, nrow = num_samples, ncol = (num_cols - 1))
  conditional_not_spam <- matrix(0, nrow = num_samples, ncol = (num_cols - 1))
  
  probability_matrix <- matrix(0, nrow = num_samples, ncol = 2)
  colnames(probability_matrix)<- c("conditional_not_spam","conditional_spam")
  # Calculate the probability density function (PDF) [Gaussian Function] for each feature of each sample in dataset.
  for (i in 1:num_samples)
  {
    for (j in 1:(num_cols - 1))
    {
      feature <- dataset[i, j]
      spam_mu <- mean_sd_matrix[j, 1]
      not_spam_mu <- mean_sd_matrix[j, 2]
      spam_sigma <- mean_sd_matrix[j, 3]
      not_spam_sigma <- mean_sd_matrix[j, 4]
      
      conditional_spam[i,j] <- (1/(sqrt(2*pi)*spam_sigma)) * exp(-(((feature - spam_mu)^2)/(2 * spam_sigma^2)))
      conditional_not_spam[i,j] <- (1/(sqrt(2*pi)*not_spam_sigma)) * exp(-(((feature - not_spam_mu)^2)/(2 * not_spam_sigma^2)))
    }
  }
  
  
  # Convert every PDF result to its log in order to add the values of each feature rather than multiply.
  # This will help avoid buffer overflow.
  conditional_spam <- log10(conditional_spam)
  conditional_not_spam <- log10(conditional_not_spam)
  
  
  # Sum the PDF results for each sample and store sum in probability_matrix
  probability_matrix[, 1] <- rowSums(conditional_not_spam)
  probability_matrix[, 2] <- rowSums(conditional_spam)
  probability_matrix[probability_matrix == '-Inf'] <- log10(.Machine$double.xmin) # Corrects buffer overflow
  
  
  # Calculate the spam & non-spam priors
  # Used https://www.theanalysisfactor.com/r-tutorial-count/ as a reference
  num_spam <- length(which(dataset[, num_cols] == 1))
  num_not_spam <- length(which(dataset[, num_cols] == 0))
  spam_prior <- num_spam / num_samples
  not_spam_prior <- num_not_spam / num_samples
  
  
  # Take the log of the spam & non-spam priors and add it to their corresponding log sums
  probability_matrix[, 1] <- probability_matrix[, 1] + log10(spam_prior)
  probability_matrix[, 2] <- probability_matrix[, 2] + log10(not_spam_prior)
  return(probability_matrix)
}

confuma <- function(dataset, probability_matrix)
{
  # Takes a matrix of spam/non-spam probabilities of each data sample and the test dataset and 
  # compares the prediction of each data sample in the probability_matrix with the target 
  # in the test data. It then creates a confusion matrix where:
  # confusion_matrix[1, 1] = Actual is non-spam and Prediction is non-spam (TN)
  # confusion_matrix[1, 2] = Actual is non-spam and Prediction is spam (FP)
  # confusion_matrix[2, 1] = Actual is spam and Prediction is non-spam (FN)
  # confusion_matrix[2, 2] = Actual is spam and Prediction is spam (TP)
  # Returns confusion matrix to the calling routine.
  
  confusion_matrix <- matrix(0, nrow = 2, ncol = 2)
  con_matrix_row_names=c("Actual Not Spam","Actual Spam")
  con_matrix_col_names=c("Predicted Not Spam","Predicted Spam")
  dimnames(confusion_matrix)=list(con_matrix_row_names,con_matrix_col_names)
  num_samples <- nrow(probability_matrix)
  max_col <- ncol(dataset)
  
  for (i in 1:num_samples)
  {
    predicted_class <- which.max(probability_matrix[i, ])
    actual_class <- dataset[i, max_col] + 1
    confusion_matrix[actual_class, predicted_class] <- confusion_matrix[actual_class, predicted_class] + 1
  }
  
  print(confusion_matrix)
  print("***************")
  return(confusion_matrix)
}


get_result <- function(confusion_matrix)
{
  accuracy <- sum(diag(confusion_matrix))#提取对角线求和
  accuracy <- accuracy / sum(confusion_matrix)#精确度=对角线和/矩阵和
  accuracy <- accuracy * 100
  #Sensitivity: TPR：true positive rate，描述识别出的所有正例占所有正例的比例 
  # #计算公式为：TPR=TP/ (TP+ FN) 
  sensitivity <- confusion_matrix[2,2]/(confusion_matrix[2,2]+confusion_matrix[2,1])
  sensitivity <- sensitivity * 100
  # #specificity TNR：true negative rate，描述识别出的负例占所有负例的比例 
  # #计算公式为：TNR= TN / (FP + TN) 
  specifity <- confusion_matrix[1,1]/(confusion_matrix[1,2]+confusion_matrix[1,1])
  specifity <- specifity * 100
  three_amigos <- c(accuracy, sensitivity, specifity)
  return(three_amigos)
}


set.seed(1)       # Set a seed so that results are reproducible
#------------------------data split-----------------------------------------------#
#read dataset and put feature names to it
spambase <- read.csv("data.csv",header=FALSE,sep=";")
names <- read.csv("names.csv",header=FALSE,sep=";")
names(spambase) <- sapply((1:nrow(names)),function(i) toString(names[i,1]))
k_folds <- 10
folds <- list()

# Split the dataset into a list of data frames where each data frame consists of randomly selected rows from the
# dataset.
# Used https://stats.stackexchange.com/questions/149250/split-data-into-n-equal-groups as a reference
folds <- split(spambase, sample(1:k_folds, nrow(spambase), replace = T))
result_list <- list() # Stores the accuracy from each fold
confusion_matrix_final <- matrix(0, nrow = 0, ncol = 2)
confusion_matrix_list <- list()
print("Confusion Matrices for each fold:")
print("TN   |   FP")
print("-----|-----")
print("FN   |   TP")
for (q in 1:10)
{
  testingData <- folds[[q]]
  trainingData <- matrix(0, nrow = 0, ncol = 58)
  for (p in 1:10)
  {
    if (p != q)
    {
      trainingData <- rbind(trainingData, folds[[p]])
    }
  }
  mean_sd_matrix <- mean_standard_dev(dataset=trainingData)
  probability_matrix <- get_class_predictions(dataset = testingData, mean_sd_matrix = mean_sd_matrix)
  confusion_matrix <- confuma(dataset = testingData,probability_matrix = probability_matrix)
  result_list[[q]] <- get_result(confusion_matrix = confusion_matrix)
  confusion_matrix_final <- rbind(confusion_matrix_final, confusion_matrix)
  print(confusion_matrix)
  
  # mean_sd_matrix <- mean_standard_dev(dataset=trainingData)
  # probability_matrix <- get_class_predictions(dataset = testingData, mean_sd_matrix = mean_sd_matrix)
  # confusion_matrix <- predict(dataset = testingData, probability_matrix = probability_matrix)
  # accuracy <- get_accuracy(confusion_matrix = confusion_matrix)
  # accuracy_list[[i]] <- accuracy
}

colnames(confusion_matrix_final) <- c("predicted_not_span","predicted_spam")
rownames(confusion_matrix_final) <- c(rep(c("actual_not_spam","actual_spam"),k_folds))
print("10 folds of confusion matrix")
print(confusion_matrix_final)

result_matrix <- matrix(unlist(result_list), ncol = 3, byrow = TRUE)
colnames(result_matrix) <- c("accuracy","sensitivity" , "specifity")
result_average <- c(mean(result_matrix[,1]),mean(result_matrix[,2]),mean(result_matrix[,3]))
result_max <- c(max(result_matrix[,1]),max(result_matrix[,2]),max(result_matrix[,3]))
result_min <- c(min(result_matrix[,1]),min(result_matrix[,2]),min(result_matrix[,3]))
result_deviation <- c(sd(result_matrix[,1]),sd(result_matrix[,2]),sd(result_matrix[,3]))
result_matrix <- rbind(result_matrix, result_average,result_max,result_min,result_deviation)
rownames(result_matrix) <- c(1:10,"ave","max","min","dev")
print("result of each fold (%):")
print(result_matrix)
