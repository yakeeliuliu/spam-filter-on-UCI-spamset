predict.dnn <- function(model, data) {
  # new data, transfer to matrix
  new.data <- data.matrix(data)
  # Feed Forwad鍓嶅悜杩愮畻閫氳繃鍓嶅悜浼犳挱绠楁硶寰楀埌鐨勮緭鍑哄眰姣忎釜缁村害鍊间唬琛ㄥ睘浜庤繖涓被鍒殑鍙兘鎬уぇ灏忋€?
  hidden.layer <- sweep(new.data %*% model$W1 ,2, model$b1, '+')#%*%涓や釜鐭╅樀鐩镐箻锛宺璇█涓娇鐢?
  #sweep(x, MARGIN, STATS, FUN="-", ...) 瀵圭煩闃佃繘琛岃繍绠椼€侻ARGIN涓?1锛岃〃绀鸿鐨勬柟鍚戜笂杩涜杩愮畻锛?
  #涓?2琛ㄧず鍒楃殑鏂瑰悜涓婅繍绠椼€係TATS鏄繍绠楃殑鍙傛暟銆侳UN涓鸿繍绠楀嚱鏁帮紝榛樿鏄噺娉曘€倄i*w1+b1 闅愬眰
  # neurons : Rectified Linear
  hidden.layer <- pmax(hidden.layer, 0)#pmax(a,b,c)#姣旇緝a,b,c鍚戦噺涓墍鏈夋暟鍊肩殑澶у皬骞跺皢鏈€澶х殑鍑犱釜鍙栧嚭
  #缁勬垚涓€涓柊鍚戦噺锛屽悜閲忛暱搴︿竴鑸姹備笁涓悜閲忔垨鏄涓悜閲忕浉鍚岋紝濡傛灉涓嶅悓锛屽垯R浼氳嚜鍔ㄥ鐞嗭紝涓€鑸舰鎴愬厓绱?
  #涓暟鏈€澶氱殑銆?
  score <- sweep(hidden.layer %*% model$W2, 2, model$b2, '+')#涓鸿緭鍑哄眰璁＄畻鍒嗘暟
  
  # Loss Function: softmax softmax濡備綍灏嗙缁忕綉缁滃墠鍚戜紶鎾緱鍒扮殑缁撴灉涔熷彉鎴愭鐜囧垎甯冨憿锛烻oftmax鍥炲綊灏辨槸涓€涓潪甯稿父鐢ㄧ殑鏂规硶銆?
  #Softmax鍥炲綊鏈韩鍙互浣滀负涓€涓涔犵畻娉曟潵浼樺寲鍒嗙被缁撴灉锛屽畠鍙槸绁炵粡缃戠粶涓殑涓€灞傞澶栫殑澶勭悊灞傦紝灏嗙缁忕綉缁滅殑杈撳嚭鍙樻垚
  #浜嗕竴涓鐜囧垎甯?
  score.exp <- exp(score)
  probs <-sweep(score.exp, 1, rowSums(score.exp), '/') 
  
  # select max possiblity
  labels.predicted <- max.col(probs)#鎵惧埌姣忎竴琛屼腑鏈€澶у€肩殑浣嶇疆锛岀鍑犲垪
  return(labels.predicted)
}

# Train: build and train a 2-layers neural network 
train.dnn <- function(x, y, traindata, testdata,model = NULL,hidden, maxit,
                      # delta loss 
                      abstol=1e-2,#Stop if the fit criterion falls below abstol, indicating an essentially perfect fit.
                      # learning rate
                      lr = 1e-2,
                      # regularization rate:it's just the additional loss generated by the
                      #regularization function. Add that to the network's loss and optimize over the sum of the two.
                      reg = 1e-3,
                      # show results every 'display' step
                      display = 100,#original is 100
                      random.seed = 1)
{
  # to make the case reproducible.
  set.seed(random.seed)
  
  # total number of training set
  N <- nrow(traindata)
  
  # extract the data and label
  # don't need atribute 
  X <- unname(data.matrix(traindata[,x]))
  # correct categories represented by integer 
  Y <- traindata[,y]
  Y <- as.integer(Y)
   # create index for both row and col
  # create index for both row and col
  Y.len   <- length(unique(Y))
  Y.set   <- sort(unique(Y))
  Y.index <- cbind(1:N, match(Y, Y.set))
  
  # create model or get model from parameter
  if(is.null(model)) {
    # number of input features
    D <- ncol(X)
    # number of categories for classification
    K <- length(unique(Y))
    H <-  hidden
    
    # create and init weights and bias: random generation for the normal distribution with mean
    W1 <- 0.01*matrix(rnorm(D*H), nrow=D, ncol=H)
    b1 <- matrix(0, nrow=1, ncol=H)#bias 鍒濆鍊间负0
    
    W2 <- 0.01*matrix(rnorm(H*K), nrow=H, ncol=K)
    b2 <- matrix(0, nrow=1, ncol=K)
  } else {
    D  <- model$D
    K  <- model$K
    H  <- model$H
    W1 <- model$W1
    b1 <- model$b1
    W2 <- model$W2
    b2 <- model$b2
  }
  
  # use all train data to update weights since it's a small dataset
  batchsize <- N
  # init loss to a very big value
  loss <- 100000
  
  # Training the network
  i <- 0
  
  while(i < maxit && loss > abstol) {
    #i < maxit && loss > abstol
    # iteration index
    i <- i + 1
    
    # forward ....
    # 1 indicate row, 2 indicate col
    hidden.layer <- sweep(X %*% W1 ,2, b1, '+')
    # neurons : ReLU
    hidden.layer <- pmax(hidden.layer, 0)
    score <- sweep(hidden.layer %*% W2, 2, b2, '+')
    
    # softmax
    score.exp <- exp(score)
    # debug
    probs <- score.exp/rowSums(score.exp)
    
    # compute the loss
    corect.logprobs <- -log(probs[Y.index])
    data.loss  <- sum(corect.logprobs)/batchsize
    reg.loss   <- 0.5*reg* (sum(W1*W1) + sum(W2*W2))
    loss <- data.loss + reg.loss
    
    # display results and update model
    if( i %% display == 0) {
      if(!is.null(testdata)) {
        model <- list( D = D,
                       H = H,
                       K = K,
                       # weights and bias
                       W1 = W1, 
                       b1 = b1, 
                       W2 = W2, 
                       b2 = b2)
        labs <- predict.dnn(model, testdata[,-y])
        accuracy <- mean(as.integer(testdata[,y]) == Y.set[labs])
        cat(i, loss, accuracy, "\n")
      } else {
        cat(i, loss, "\n")
      }
    }
    
    # backward ....
    dscores <- probs
    dscores[Y.index] <- dscores[Y.index] - 1
    dscores <- dscores / batchsize
    
    
    dW2 <- t(hidden.layer) %*% dscores 
    db2 <- colSums(dscores)
    
    dhidden <- dscores %*% t(W2)
    dhidden[hidden.layer <= 0] <- 0
    
    dW1 <- t(X) %*% dhidden
    db1 <- colSums(dhidden) 
    
    # update ....
    dW2 <- dW2 + reg*W2
    dW1 <- dW1  + reg*W1
    
    W1 <- W1 - lr * dW1
    b1 <- b1 - lr * db1
    
    W2 <- W2 - lr * dW2
    b2 <- b2 - lr * db2
    
    
    
  }
  
  # final results
  # creat list to store learned parameters
  # you can add more parameters for debug and visualization
  # such as residuals, fitted.values ...
  model <- list( D = D,
                 H = H,
                 K = K,
                 # weights and bias
                 W1= W1, 
                 b1= b1, 
                 W2= W2, 
                 b2= b2)
  
  return(model)
}

########################################################################
# testing
#######################################################################
set.seed(1)

# 0. EDA
dataset <- read.csv("data.csv",header=FALSE,sep=";")
names <- read.csv("names.csv",header=FALSE,sep=";")
names(dataset) <- sapply((1:nrow(names)),function(i) toString(names[i,1]))

library('UBL')
dataset <- ENNClassif( y~., dat=dataset, k = 3, dist = "Euclidean", Cl = c(1,0))
c <- as.data.frame(dataset[[1]])
dataset <- c

resize <- sample(1:3749,1000)
dataset <- dataset[resize,]

k_folds <- 3
folds <- list()

# Split the dataset into a list of data frames where each data frame consists of randomly selected rows from the
# dataset.
# Used https://stats.stackexchange.com/questions/149250/split-data-into-n-equal-groups as a reference
folds <- split(dataset, sample(1:k_folds, nrow(dataset), replace = T))
result_matrix <- matrix(0,nrow = 0,ncol = 3) # Stores the accuracy from each fold

for (q in 1:k_folds)
{
  testingData <- folds[[q]]
  trainingData <- matrix(0, nrow = 0, ncol = 58)
  for (p in 1:k_folds)
  {
    if (p != q)
    {
      trainingData <- rbind(trainingData, folds[[p]])
    }
  }
  # 2. train model
  spam.model <- train.dnn(x=1:57, y=58, traindata=trainingData, testdata=testingData, hidden=50, maxit=20000)
   spam.model
  # 3. prediction
   labels.dnn <- predict.dnn(spam.model, testingData[, -57])
   labels.dnn <- labels.dnn - 1
   # 4. verify the results
   table.dnn<-table(testingData[,58], labels.dnn,dnn=c("actual","predicted"))
   table.dnn 
   #accuracy
  mean(as.integer(testingData[,58]) == labels.dnn)
  acuracy <- 100*(table.dnn[1,1] + table.dnn[2,2]) / sum(table.dnn)
  specifity <- 100*table.dnn[1,1]/(table.dnn[1,2]+table.dnn[1,1]) 
  sensitivity <- 100*table.dnn[2,2]/(table.dnn[2,2]+table.dnn[2,1])
  matrix_once <- matrix(c(acuracy,sensitivity,specifity), nrow=1 , ncol=3)
  result_matrix <- rbind(result_matrix,matrix_once)
  
 }

colnames(result_matrix) <- c("accuracy","sensitivity" , "specifity")
result_average <- c(mean(result_matrix[,1]),mean(result_matrix[,2]),mean(result_matrix[,3]))
result_max <- c(max(result_matrix[,1]),max(result_matrix[,2]),max(result_matrix[,3]))
result_min <- c(min(result_matrix[,1]),min(result_matrix[,2]),min(result_matrix[,3]))
result_deviation <- c(sd(result_matrix[,1]),sd(result_matrix[,2]),sd(result_matrix[,3]))
result_matrix <- rbind(result_matrix, result_average,result_max,result_min,result_deviation)
rownames(result_matrix) <- c(1:k_folds,"ave","max","min","dev")
print(result_matrix)



# # Choose 3680 objects randomly  for training sample data from 4601 objects(vectors):
# trainingIndex <- sample(1:4601,trainingSize)
# # Divide the data set into training data and test data:
# trainingData<-dataset[trainingIndex,]
# testingData<-dataset[-trainingIndex,]
# summary(dataset)
# spam_count <- sum(testingData$y == 1)
# print("spam numner in testing data")
# spam_count
# ham_count <- sum(testingData$y == 0)
# print("non-spam numner in testing data")
# ham_count

